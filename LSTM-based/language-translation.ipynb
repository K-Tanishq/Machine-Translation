{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2936819,"sourceType":"datasetVersion","datasetId":1800581}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nfrom torchtext.datasets import Multi30k\nimport numpy as np\nimport pandas as pd\nimport spacy\nimport random\nimport re\nimport string\nimport torchtext\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:00.085976Z","iopub.execute_input":"2024-05-22T09:42:00.086813Z","iopub.status.idle":"2024-05-22T09:42:00.093560Z","shell.execute_reply.started":"2024-05-22T09:42:00.086777Z","shell.execute_reply":"2024-05-22T09:42:00.092343Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:00.099719Z","iopub.execute_input":"2024-05-22T09:42:00.100084Z","iopub.status.idle":"2024-05-22T09:42:00.107431Z","shell.execute_reply.started":"2024-05-22T09:42:00.100056Z","shell.execute_reply":"2024-05-22T09:42:00.106355Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"torch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\nepochs = 50","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:00.109280Z","iopub.execute_input":"2024-05-22T09:42:00.110177Z","iopub.status.idle":"2024-05-22T09:42:00.116602Z","shell.execute_reply.started":"2024-05-22T09:42:00.110128Z","shell.execute_reply":"2024-05-22T09:42:00.115648Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"embedding_size = 300\nhidden_size = 1024\nnum_layers = 2\ndropout = 0.5\ndropout = 0.5","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:00.117667Z","iopub.execute_input":"2024-05-22T09:42:00.117940Z","iopub.status.idle":"2024-05-22T09:42:00.125848Z","shell.execute_reply.started":"2024-05-22T09:42:00.117917Z","shell.execute_reply":"2024-05-22T09:42:00.124944Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"learning_rate = 3e-4\nbatch_size =32","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:00.128260Z","iopub.execute_input":"2024-05-22T09:42:00.128741Z","iopub.status.idle":"2024-05-22T09:42:00.134646Z","shell.execute_reply.started":"2024-05-22T09:42:00.128704Z","shell.execute_reply":"2024-05-22T09:42:00.133620Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"!python -m spacy download de_core_news_sm\n!python -m spacy download en_core_web_sm","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:00.135909Z","iopub.execute_input":"2024-05-22T09:42:00.136912Z","iopub.status.idle":"2024-05-22T09:42:38.404094Z","shell.execute_reply.started":"2024-05-22T09:42:00.136874Z","shell.execute_reply":"2024-05-22T09:42:38.402787Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Collecting de-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from de-core-news-sm==3.7.0) (3.7.3)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.3)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('de_core_news_sm')\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.3)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"spacy_ger = spacy.load('de_core_news_sm')\nspacy_eng = spacy.load('en_core_web_sm')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:38.407456Z","iopub.execute_input":"2024-05-22T09:42:38.407925Z","iopub.status.idle":"2024-05-22T09:42:41.588854Z","shell.execute_reply.started":"2024-05-22T09:42:38.407879Z","shell.execute_reply":"2024-05-22T09:42:41.587615Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"class Vocabulary:\n    def __init__(self, freq_threshold):\n        self.itos = {0:\"<PAD>\", 1:\"<SOS>\", 2:\"<EOS>\", 3:\"<UNK>\"}\n        self.stoi = {\"<PAD>\":0, \"<SOS>\":1, \"<EOS>\":2, \"<UNK>\":3}\n        self.freq_threshold  = freq_threshold\n        \n    def __len__(self):\n        return len(self.itos)\n    \n    @staticmethod\n    def preprocessing_text(text):\n        text = text.lower().strip()\n        text = re.sub(f'[{string.punctuation}\\n]', '', text)\n        return text\n    \n    @staticmethod\n    def tokenizer_ger(text):\n        text = Vocabulary.preprocessing_text(text)\n        return [tok.text for tok in spacy_ger.tokenizer(text)]\n    \n    @staticmethod\n    def tokenizer_eng(text):\n        text = Vocabulary.preprocessing_text(text)\n        return [tok.text for tok in spacy_eng.tokenizer(text)]\n    \n    def build_vocabulary(self, sentence_list):\n        frequencies = {}\n        index = 4\n        \n        for sentence in sentence_list:\n            for word in self.tokenizer_eng(sentence):\n                if word not in frequencies:\n                    frequencies[word] = 1\n                else:\n                    frequencies[word] += 1\n                    \n                if frequencies[word] == self.freq_threshold:\n                    self.stoi[word] = index\n                    self.itos[index] = word\n                    index += 1\n            \n            for word in self.tokenizer_ger(sentence):\n                if word not in frequencies:\n                    frequencies[word] = 1\n                else:\n                    frequencies[word] += 1\n                    \n                if frequencies[word] == self.freq_threshold:\n                    self.stoi[word] = index\n                    self.itos[index] = word\n                    index += 1\n                    \n    def numericalize(self, text, lang=\"eng\"):\n        if lang == \"eng\":\n            tokenized_text = self.tokenizer_eng(text)\n        else:\n            tokenized_text = self.tokenizer_ger(text)\n            \n        return [\n            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n            for token in tokenized_text\n        ]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:41.590326Z","iopub.execute_input":"2024-05-22T09:42:41.590664Z","iopub.status.idle":"2024-05-22T09:42:41.606645Z","shell.execute_reply.started":"2024-05-22T09:42:41.590633Z","shell.execute_reply":"2024-05-22T09:42:41.605542Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class MyCollate:\n    def __init__(self, pad_index):\n        self.pad_index = pad_index\n        \n    def __call__(self, batch):\n        eng = [item[0] for item in batch]\n        eng = pad_sequence(eng, batch_first=False, padding_value = self.pad_index)\n        ger = [item[1] for item in batch]\n        ger = pad_sequence(ger, batch_first=False, padding_value = self.pad_index)\n        return eng, ger","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:41.608051Z","iopub.execute_input":"2024-05-22T09:42:41.608452Z","iopub.status.idle":"2024-05-22T09:42:41.618376Z","shell.execute_reply.started":"2024-05-22T09:42:41.608422Z","shell.execute_reply":"2024-05-22T09:42:41.617478Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class Multi30K_Custom(Dataset):\n    def __init__(self, csv_file, transform = None, freq_threshold = 5):\n        self.csv_file = csv_file\n        self.data = pd.read_csv(csv_file)\n        self.eng = self.data[\"english\"]\n        self.ger = self.data[\"german\"]\n        self.vocab_eng = Vocabulary(freq_threshold)\n        self.vocab_eng.build_vocabulary(self.eng.tolist())\n        self.vocab_ger = Vocabulary(freq_threshold)\n        self.vocab_ger.build_vocabulary(self.ger.tolist())\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def eng_vocab_len(self):\n        return len(self.vocab_eng)\n    \n    def ger_vocab_len(self):\n        return len(self.vocab_ger)\n    \n    def __getitem__(self, index):\n        eng = self.eng[index]\n        ger = self.ger[index]\n        eng_cap = [self.vocab_eng.stoi[\"<SOS>\"]]\n        eng_cap += self.vocab_eng.numericalize(eng)\n        eng_cap.append(self.vocab_eng.stoi[\"<EOS>\"])\n        ger_cap = [self.vocab_ger.stoi[\"<SOS>\"]]\n        ger_cap += self.vocab_ger.numericalize(eng)\n        ger_cap.append(self.vocab_ger.stoi[\"<EOS>\"])\n        return torch.tensor(eng_cap), torch.tensor(ger_cap)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:41.619683Z","iopub.execute_input":"2024-05-22T09:42:41.620595Z","iopub.status.idle":"2024-05-22T09:42:41.631629Z","shell.execute_reply.started":"2024-05-22T09:42:41.620560Z","shell.execute_reply":"2024-05-22T09:42:41.630563Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"train_data = Multi30K_Custom(\"/kaggle/input/machine-translation-dataset-de-en/translation_train.csv\")\ntest_data = Multi30K_Custom(\"/kaggle/input/machine-translation-dataset-de-en/translation_test.csv\")\neng_pad_index = train_data.vocab_eng.stoi[\"<PAD>\"]\nger_pad_index = train_data.vocab_ger.stoi[\"<PAD>\"]\ntrain_loader = DataLoader(train_data, batch_size, shuffle=True, collate_fn=MyCollate(eng_pad_index))\ntest_loader = DataLoader(test_data, batch_size, shuffle=True, collate_fn=MyCollate(ger_pad_index))","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:41.632993Z","iopub.execute_input":"2024-05-22T09:42:41.633364Z","iopub.status.idle":"2024-05-22T09:42:52.186707Z","shell.execute_reply.started":"2024-05-22T09:42:41.633328Z","shell.execute_reply":"2024-05-22T09:42:52.185855Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"eng_vocab = train_data.vocab_eng\nger_vocab = train_data.vocab_ger\neng_vocab_len = train_data.eng_vocab_len()\nger_vocab_len = train_data.ger_vocab_len()\ninput_encoder = ger_vocab_len\ninput_decoder = eng_vocab_len\noutput_size = eng_vocab_len","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:52.189475Z","iopub.execute_input":"2024-05-22T09:42:52.189815Z","iopub.status.idle":"2024-05-22T09:42:52.195122Z","shell.execute_reply.started":"2024-05-22T09:42:52.189786Z","shell.execute_reply":"2024-05-22T09:42:52.194008Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, hidden_size, embedding_size, num_layers, p):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.dropout = nn.Dropout(p)\n        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n        \n    def forward(self, x):   # (seq_length, batch_size)\n        x = self.embedding(x)  # (seq_length, batch_size, embedding_size)\n        x = self.dropout(x)\n        output, (hidden, cell) = self.lstm(x)\n        return output, hidden, cell","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:52.196356Z","iopub.execute_input":"2024-05-22T09:42:52.196692Z","iopub.status.idle":"2024-05-22T09:42:52.205008Z","shell.execute_reply.started":"2024-05-22T09:42:52.196664Z","shell.execute_reply":"2024-05-22T09:42:52.204007Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, input_size, hidden_size, embedding_size, num_layers, output_size, p):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.embedding = nn.Embedding(input_size, embedding_size)\n        self.dropout = nn.Dropout(p)\n        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n        self.fc = nn.Linear(hidden_size, output_size)\n        \n    def forward(self, x, hidden, cell):   # (batch_size) but want (1, batch_size)\n        x = x.view(1, x.size(0))\n        x = self.embedding(x)  # (1, batch_size, embedding_size)\n        x = self.dropout(x)\n        outputs, (hidden, cell) = self.lstm(x)  # output --> (1, batch_size, hidden_size)\n        predictions = self.fc(outputs)  # (1, batch_size, vocab_eng)\n        predictions = predictions.squeeze(0)\n        return predictions, hidden, cell","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:52.206449Z","iopub.execute_input":"2024-05-22T09:42:52.206821Z","iopub.status.idle":"2024-05-22T09:42:52.217352Z","shell.execute_reply.started":"2024-05-22T09:42:52.206794Z","shell.execute_reply":"2024-05-22T09:42:52.216324Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class Translator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.encoder = Encoder(input_encoder, hidden_size, embedding_size, num_layers, dropout)\n        self.decoder = Decoder(input_decoder, hidden_size, embedding_size, num_layers, output_size, dropout)\n        \n    def forward(self, source, target, teacher_force_ratio = 0.5):\n        batch_size = source.shape[1]\n        target_len = target.shape[0]\n        target_vocab_size = eng_vocab_len\n        \n        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n        _, hidden, cell = self.encoder(source)\n        x = target[0]\n        for t in range(1, target_len):\n            output, hidden, cell = self.decoder(x, hidden, cell)\n            outputs[t] = output\n            best_guess = output.argmax(1)\n            x = target[t] if random.random() < teacher_force_ratio else best_guess\n            return outputs","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:52.218673Z","iopub.execute_input":"2024-05-22T09:42:52.219035Z","iopub.status.idle":"2024-05-22T09:42:52.229412Z","shell.execute_reply.started":"2024-05-22T09:42:52.219001Z","shell.execute_reply":"2024-05-22T09:42:52.228360Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"model = Translator().to(device)\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\ncriterion = nn.CrossEntropyLoss(ignore_index=eng_pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:52.230762Z","iopub.execute_input":"2024-05-22T09:42:52.231096Z","iopub.status.idle":"2024-05-22T09:42:52.642746Z","shell.execute_reply.started":"2024-05-22T09:42:52.231070Z","shell.execute_reply":"2024-05-22T09:42:52.641944Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"t_loss = []\nfor epoch in range(epochs):\n    model.train()\n    train_loss = 0\n    for batch_idx, (eng, ger) in enumerate(train_loader):\n        optimizer.zero_grad()\n        eng = eng.to(device)\n        ger = ger.to(device)\n        output = model(ger, eng)\n        output = output[1:].reshape(-1, output.shape[2])\n        eng = eng[1:].reshape(-1)\n        loss = criterion(output, eng)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n        train_loss += loss.item()\n        optimizer.step()\n    train_loss /= len(train_loader)\n    t_loss.append(train_loss)\n    print(f'Epoch {epoch+1}, Train Loss: {train_loss}')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:42:52.643861Z","iopub.execute_input":"2024-05-22T09:42:52.644151Z","iopub.status.idle":"2024-05-22T09:58:53.951900Z","shell.execute_reply.started":"2024-05-22T09:42:52.644125Z","shell.execute_reply":"2024-05-22T09:58:53.950839Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Epoch 1, Train Loss: 7.947397762517288\nEpoch 2, Train Loss: 7.934791579661848\nEpoch 3, Train Loss: 7.934518496545962\nEpoch 4, Train Loss: 7.934014799313614\nEpoch 5, Train Loss: 7.933949411112524\nEpoch 6, Train Loss: 7.934088987710063\nEpoch 7, Train Loss: 7.933795534131808\nEpoch 8, Train Loss: 7.933719405265732\nEpoch 9, Train Loss: 7.933795636649169\nEpoch 10, Train Loss: 7.933539807467897\nEpoch 11, Train Loss: 7.933519842343399\nEpoch 12, Train Loss: 7.933554942710397\nEpoch 13, Train Loss: 7.933818928067713\nEpoch 14, Train Loss: 7.933527850789298\nEpoch 15, Train Loss: 7.933509988585013\nEpoch 16, Train Loss: 7.933554111005453\nEpoch 17, Train Loss: 7.933248681296587\nEpoch 18, Train Loss: 7.9335782504265735\nEpoch 19, Train Loss: 7.933573734931147\nEpoch 20, Train Loss: 7.933711280107761\nEpoch 21, Train Loss: 7.933812526778586\nEpoch 22, Train Loss: 7.933521012092767\nEpoch 23, Train Loss: 7.933637853494158\nEpoch 24, Train Loss: 7.93331409841283\nEpoch 25, Train Loss: 7.933529851192151\nEpoch 26, Train Loss: 7.933288961681799\nEpoch 27, Train Loss: 7.933442152584795\nEpoch 28, Train Loss: 7.933262919117887\nEpoch 29, Train Loss: 7.93346545346648\nEpoch 30, Train Loss: 7.933360013572751\nEpoch 31, Train Loss: 7.93350551935383\nEpoch 32, Train Loss: 7.933449099055987\nEpoch 33, Train Loss: 7.9333312571903045\nEpoch 34, Train Loss: 7.933377065101295\nEpoch 35, Train Loss: 7.93336385140214\nEpoch 36, Train Loss: 7.933459528488782\nEpoch 37, Train Loss: 7.933565516193226\nEpoch 38, Train Loss: 7.933551989158959\nEpoch 39, Train Loss: 7.933351557204847\nEpoch 40, Train Loss: 7.933362910345345\nEpoch 41, Train Loss: 7.933172272216393\nEpoch 42, Train Loss: 7.933388508141633\nEpoch 43, Train Loss: 7.9332948467040145\nEpoch 44, Train Loss: 7.933354806216576\nEpoch 45, Train Loss: 7.933190349444271\nEpoch 46, Train Loss: 7.933396199046579\nEpoch 47, Train Loss: 7.933143898565425\nEpoch 48, Train Loss: 7.933419375330242\nEpoch 49, Train Loss: 7.933319336261349\nEpoch 50, Train Loss: 7.933438812096037\n","output_type":"stream"}]},{"cell_type":"code","source":"def translate_sentence(model, sentence, src_vocab, trg_vocab, device, max_length=50):\n    # Set the model to evaluation mode\n    model.eval()\n    \n    # Tokenize and numericalize the input sentence\n    tokens = [token.text.lower() for token in spacy_ger.tokenizer(sentence)]\n    numericalized_tokens = [src_vocab.stoi[\"<SOS>\"]] + [src_vocab.stoi.get(token, src_vocab.stoi[\"<UNK>\"]) for token in tokens] + [src_vocab.stoi[\"<EOS>\"]]\n    sentence_tensor = torch.tensor(numericalized_tokens).unsqueeze(1).to(device)\n    \n    # Feed the input to the encoder\n    with torch.no_grad():\n        hidden = model.encoder(sentence_tensor)\n    \n    # Initialize the decoder input with <SOS>\n    x = torch.tensor([trg_vocab.stoi[\"<SOS>\"]], dtype=torch.long).to(device)\n    \n    translated_sentence = []\n    cell = tuple(torch.zeros_like(h) for h in hidden)  # Initialize cell state\n    \n    for _ in range(max_length):\n        with torch.no_grad():\n            output, hidden, cell = model.decoder(x, hidden, cell)  # Pass both hidden and cell states to decoder\n            pred_token = output.argmax(1).item()\n            translated_sentence.append(pred_token)\n            x = torch.tensor([[pred_token]], dtype=torch.long).to(device)  # Corrected shape for the decoder input\n            if pred_token == trg_vocab.stoi[\"<EOS>\"]:\n                break\n    \n    translated_tokens = [trg_vocab.itos[idx] for idx in translated_sentence]\n    \n    return translated_tokens\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:58:53.953394Z","iopub.execute_input":"2024-05-22T09:58:53.953907Z","iopub.status.idle":"2024-05-22T09:58:53.969570Z","shell.execute_reply.started":"2024-05-22T09:58:53.953867Z","shell.execute_reply":"2024-05-22T09:58:53.968567Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"sentence = \"ein kleines mädchen spielt im garten\"\ntranslated_sentence = translate_sentence(model, sentence, ger_vocab, eng_vocab, device)\ntranslated_sentence = ' '.join(translated_sentence)\nprint(f\"Translated Sentence: {translated_sentence}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T09:58:53.970897Z","iopub.execute_input":"2024-05-22T09:58:53.971274Z","iopub.status.idle":"2024-05-22T09:58:54.017558Z","shell.execute_reply.started":"2024-05-22T09:58:53.971239Z","shell.execute_reply":"2024-05-22T09:58:54.016547Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Translated Sentence: a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine a tambourine\n","output_type":"stream"}]}]}